{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import facenet\n",
    "import detect_face\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "datadir = '/home/neelansh/vggface_aligned/'\n",
    "model_dir = '/home/neelansh/Face-recognition-real-time/models/20170512-110547-center-loss/20170512-110547.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class, nrof_test_images_per_class):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for cls in dataset:\n",
    "        paths = cls.image_paths\n",
    "        # Remove classes with less than min_nrof_images_per_class\n",
    "        if len(paths)>=min_nrof_images_per_class:\n",
    "            np.random.shuffle(paths)\n",
    "            train_set.append(facenet.ImageClass(cls.name, paths[:nrof_train_images_per_class]))\n",
    "            test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:nrof_train_images_per_class+nrof_test_images_per_class]))\n",
    "    return train_set, test_set\n",
    "\n",
    "dataset = facenet.get_dataset(datadir)\n",
    "(train_set, test_set) = split_dataset(dataset, 10, 8, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(dataset, modeldir, batch_size = 256, image_size = 160):\n",
    "    paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model(modeldir)\n",
    "\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Calculating features for images')\n",
    "\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i * batch_size\n",
    "                end_index = min((i + 1) * batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, True, image_size)\n",
    "                feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n",
    "                emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            print('DONE')\n",
    "            return emb_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating fetures for train\n",
      "Loading feature extraction model\n",
      "Model filename: /home/neelansh/Face-recognition-real-time/models/20170512-110547-center-loss/20170512-110547.pb\n",
      "Calculating features for images\n"
     ]
    }
   ],
   "source": [
    "print('calculating fetures for train')\n",
    "train_embeddings = get_embeddings(train_set, model_dir)\n",
    "print('calculating fetures for test')\n",
    "test_embeddings = get_embeddings(test_set, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "Testing classifier\n",
      "accuracy Linear SVM:  0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "train_paths, train_labels = facenet.get_image_paths_and_labels(train_set)\n",
    "test_paths, test_labels = facenet.get_image_paths_and_labels(test_set)\n",
    "\n",
    "# Train classifier\n",
    "print('Training classifier')\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(train_embeddings, train_labels)\n",
    "\n",
    "print('Testing classifier')\n",
    "pred = model.predict(test_embeddings)\n",
    "\n",
    "print('accuracy Linear SVM: ', accuracy_score(test_labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier model to file \"./models/svm_linear_center_vggsample.pkl\"\n"
     ]
    }
   ],
   "source": [
    "# Create a list of class names\n",
    "class_names = [cls.name.replace('_', ' ') for cls in train_set]\n",
    "\n",
    "classifier_filename = './models/svm_linear_center_vggsample.pkl'\n",
    "classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "# Saving classifier model\n",
    "with open(classifier_filename_exp, 'wb') as outfile:\n",
    "    pickle.dump((model, class_names), outfile)\n",
    "print('Saved classifier model to file \"%s\"' % classifier_filename_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17338818504593856\n",
      "/home/neelansh/vgg_sample/n000006/0241_03.jpg\n",
      "n000003\n"
     ]
    }
   ],
   "source": [
    "# Wrongly classified\n",
    "for idx, item in enumerate(pred):\n",
    "    if(item != test_labels[idx]):\n",
    "        print(np.max(pred_prob[idx]))\n",
    "        print(test_paths[idx])\n",
    "        print(class_names[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Testing classifier\n",
      "accuracy KNN:  0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "print('Fitting')\n",
    "neigh.fit(train_embeddings, train_labels)\n",
    "\n",
    "print('Testing classifier')\n",
    "knn_pred = neigh.predict(test_embeddings)\n",
    "\n",
    "print('accuracy KNN: ', accuracy_score(test_labels, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved classifier model to file \"./models/knn_3_center_vggsample.pkl\"\n"
     ]
    }
   ],
   "source": [
    "# Create a list of class names\n",
    "class_names = [cls.name.replace('_', ' ') for cls in train_set]\n",
    "\n",
    "classifier_filename = './models/knn_3_center_vggsample.pkl'\n",
    "classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "# Saving classifier model\n",
    "with open(classifier_filename_exp, 'wb') as outfile:\n",
    "    pickle.dump((neigh, class_names), outfile)\n",
    "print('Saved classifier model to file \"%s\"' % classifier_filename_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1.23177508, 1.24187557, 1.24476892]]), array([[ 7, 18,  0]]))\n",
      "/home/neelansh/vgg_sample/n000006/0241_03.jpg\n",
      "Neelansh\n",
      "(array([[0.7857633 , 0.90686242, 0.924861  ]]), array([[ 76,  79, 163]]))\n",
      "/home/neelansh/vgg_sample/n000022/0048_02.jpg\n",
      "n000011\n"
     ]
    }
   ],
   "source": [
    "#Wrongly classified\n",
    "for idx, item in enumerate(knn_pred):\n",
    "    if(item != test_labels[idx]):\n",
    "        print(neigh.kneighbors([test_embeddings[idx]]))\n",
    "        print(test_paths[idx])\n",
    "        print(class_names[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = './models/vggface2.pkl'\n",
    "dataset_filename_exp = os.path.expanduser(dataset_filename)\n",
    "# Saving classifier model\n",
    "with open(dataset_filename_exp, 'wb') as outfile:\n",
    "    pickle.dump((train_embeddings, test_embeddings, train_labels, test_labels), outfile)\n",
    "print('Saved dataset embeddings to file \"%s\"' % dataset_filename_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
